# rotation_invariant_checking.py
import numpy as np
import cv2
from typing import List, Dict, Tuple, Any, Optional
import math
import traceback
import time  # Import time module


# --- Helper Function for MASK IoU Calculation (Assumes boolean inputs) ---
def calculate_iou(mask1_bool: np.ndarray, mask2_bool: np.ndarray) -> float:
    """Calculates Intersection over Union (IoU) for two boolean masks."""
    intersection = np.sum(mask1_bool & mask2_bool)
    union = np.sum(mask1_bool | mask2_bool)
    return float(intersection / union) if union > 0 else 0.0


# --- Helper Function for Bounding Box IoU (User's Original Version) ---
def calculate_bbox_iou(box1: List[int], box2: List[int]) -> float:
    """
    Calculates IoU for two bounding boxes [x1, y1, x2, y2].
    Uses +1 logic suitable for inclusive pixel coordinates.
    """
    x1_i, y1_i, x2_i, y2_i = box1
    x1_j, y1_j, x2_j, y2_j = box2

    # Determine the coordinates of the intersection rectangle
    x_left = max(x1_i, x1_j)
    y_top = max(y1_i, y1_j)
    x_right = min(x2_i, x2_j)
    y_bottom = min(y2_i, y2_j)

    # If width or height of intersection is negative, no overlap
    if x_right < x_left or y_bottom < y_top:
        return 0.0

    # Calculate intersection area (ensure width/height are non-negative)
    # Add 1 because coordinates are inclusive pixel indices
    intersection_area = (x_right - x_left + 1) * (y_bottom - y_top + 1)

    # Calculate area of both bounding boxes (using +1 for inclusive coords)
    area1 = (x2_i - x1_i + 1) * (y2_i - y1_i + 1)
    area2 = (x2_j - x1_j + 1) * (y2_j - y1_j + 1)

    # Calculate union area
    union_area = float(area1 + area2 - intersection_area)

    # Handle division by zero
    if union_area <= 0:
        return 0.0
    else:
        iou = intersection_area / union_area
        return float(iou)


# --- End Helper Function ---


class RotationInvariantAOIChecker:
    """
    Checks masks based on features and spatial constraints. Includes detailed timing.
    Workflow: Edge->(Optional)MaskIoU->Feature->BBoxNMS->Distance->Containment->RelPos->Count->Overlap
    """

    def __init__(self, config: Dict[str, Any]):
        """
        Initializes the checker with configuration loaded from a dictionary.

        Args:
            config (Dict[str, Any]): The configuration dictionary, typically loaded
                                     from the JSON generated by the learning tool.
                                     Expected keys: "target_objects", "distance_constraints",
                                     "relative_position_constraints", "overlap_rules",
                                     and optionally "internal_geometry_checks".
        """
        if not isinstance(config, dict): raise ValueError("Configuration must be a dictionary.")
        print("[Init] Loading configuration...")
        self.config = config
        self.target_objects = config.get("target_objects", {})
        self.distance_constraints = config.get("distance_constraints", {})
        self.overlap_rules = config.get("overlap_rules", [])
        self.relative_position_constraints = config.get("relative_position_constraints", {})
        # --- NEW: Parse internal geometry checks ---
        self.internal_geometry_checks_config = config.get("internal_geometry_checks", {})
        # --- End NEW ---

        # --- Configuration Parsing and Validation ---
        target_objects_dict = self.target_objects
        if target_objects_dict and isinstance(target_objects_dict, dict):
            for spec in target_objects_dict.values():
                if isinstance(spec, dict) and "feature_ranges" in spec and isinstance(spec["feature_ranges"], dict):
                    for key, value in spec["feature_ranges"].items():
                        if isinstance(value, list) and len(value) == 2:
                            try:
                                spec["feature_ranges"][key] = tuple(map(float, value))
                            except (ValueError, TypeError):
                                print(f"[Warning][Init] Invalid feature range {key}: {value}.")

        if self.distance_constraints and isinstance(self.distance_constraints, dict):
            for constraint in self.distance_constraints.values():
                if isinstance(constraint, dict) and "range" in constraint and isinstance(constraint["range"],
                                                                                         list) and len(
                    constraint["range"]) == 2:
                    try:
                        constraint["range"] = tuple(map(float, constraint["range"]))
                    except (ValueError, TypeError):
                        print(f"[Warning][Init] Invalid distance range: {constraint['range']}.")

        if self.relative_position_constraints and isinstance(self.relative_position_constraints, dict):
            for constraint in self.relative_position_constraints.values():
                valid = True
                if isinstance(constraint, dict):
                    for key in ["dx_range", "dy_range"]:
                        value = constraint.get(key)
                        if isinstance(value, list) and len(value) == 2:
                            try:
                                constraint[key] = tuple(map(float, value))
                            except (ValueError, TypeError):
                                print(f"[Warning][Init] Invalid relative pos range {key}: {value}.")
                                valid = False
                                break
                        else:
                            print(f"[Warning][Init] Invalid relative pos format {key}: {value}.")
                            valid = False
                            break
                else:
                    valid = False
                    print(f"[Warning][Init] Invalid relative pos constraint format: {constraint}")

        # Prepare classification rules list
        self.classification_rules = []
        if target_objects_dict and isinstance(target_objects_dict, dict):
            for obj_type, spec in target_objects_dict.items():
                if isinstance(spec, dict) and "feature_ranges" in spec and "expected_evaluation_count" in spec:
                    feature_ranges = spec.get("feature_ranges", {})
                    expected_eval_count = spec.get("expected_evaluation_count", 0)
                    self.classification_rules.append(
                        {'type': obj_type, 'ranges': feature_ranges, 'expected_count': expected_eval_count})
            print(f"[Init] Loaded {len(self.classification_rules)} classification rules.")
        else:
            print("[Warning][Init] 'target_objects' missing or invalid.")

        # Print summary of loaded constraints
        if self.distance_constraints: print(
            f"[Init] Loaded {len(self.distance_constraints)} distance constraint rule(s).")
        if self.relative_position_constraints: print(
            f"[Init] Loaded {len(self.relative_position_constraints)} relative position constraint rule(s).")
        if self.overlap_rules: print(f"[Init] Loaded {len(self.overlap_rules)} overlap rule(s).")
        # --- NEW: Log internal geometry checks ---
        if self.internal_geometry_checks_config: print(
            f"[Init] Loaded {len(self.internal_geometry_checks_config)} internal geometry check configuration(s).")
        # --- End NEW ---
        print("[Init] RotationInvariantAOIChecker Initialized.")
        # --- End Configuration Parsing ---

    def extract_features(self, mask: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        Computes geometric and positional features for a single mask.

        Includes: area, aspect ratio, centroid, perimeter, larger/smaller dimensions
                  of the minimum rotated rectangle, angle of the rectangle, vertices
                  of the rectangle, and the axis-aligned bounding box.

        Args:
            mask (np.ndarray): A 2D NumPy array (uint8 or bool) representing the mask.

        Returns:
            Optional[Dict[str, Any]]: A dictionary containing the extracted features,
                                      or None if the mask is invalid or empty.
        """
        if not isinstance(mask, np.ndarray) or mask.ndim != 2: return None
        # Ensure mask is uint8 for OpenCV functions
        if mask.dtype != np.uint8:
            mask_uint8 = mask.astype(np.uint8)
        else:
            mask_uint8 = mask

        area = float(np.sum(mask_uint8 > 0))
        if area == 0: return None  # Skip empty masks

        # Get pixel coordinates
        y_indices, x_indices = np.where(mask_uint8 > 0)
        if len(x_indices) == 0 or len(y_indices) == 0: return None  # Should not happen if area > 0

        # --- Axis-aligned Bounding Box (Inclusive Pixel Coords) ---
        x1, y1 = int(np.min(x_indices)), int(np.min(y_indices))
        x2, y2 = int(np.max(x_indices)), int(np.max(y_indices))
        bbox = [x1, y1, x2, y2]  # Format: [x_min, y_min, x_max, y_max]

        # --- Centroid ---
        # Using mean of coordinates is often more robust for non-convex shapes than moments
        centroid_x, centroid_y = float(np.mean(x_indices)), float(np.mean(y_indices))

        # --- Minimum Area Rotated Rectangle Features ---
        points = np.column_stack((x_indices, y_indices)).astype(np.float32)
        angle = 0.0
        min_rect_vertices = None
        raw_width, raw_height = 0.0, 0.0
        try:
            # Calculate the minimum area rectangle enclosing the mask points
            rect = cv2.minAreaRect(points)
            # rect format: ((center_x, center_y), (width, height), angle)
            raw_width, raw_height = rect[1]  # Width and height of the rectangle
            angle = float(rect[2])  # Angle (-90 to 0 degrees)
            # Get the 4 vertices of the rotated rectangle
            box = cv2.boxPoints(rect)
            min_rect_vertices = box  # Keep as float initially if needed, convert later
        except cv2.error:
            print("[Warning][Features] cv2.minAreaRect failed.")  # Handle potential OpenCV errors

        # Ensure width/height are non-negative
        raw_width = max(0.0, raw_width)
        raw_height = max(0.0, raw_height)

        larger_dim = float(max(raw_width, raw_height))
        smaller_dim = float(min(raw_width, raw_height))
        aspect_ratio = smaller_dim / larger_dim if larger_dim > 0 else 0.0

        # --- Perimeter (from contour) ---
        perimeter = 0.0
        try:
            # Find contours (external only)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                # Use the largest contour found (usually the main object)
                largest_contour = max(contours, key=cv2.contourArea)
                perimeter = float(cv2.arcLength(largest_contour, closed=True))
        except cv2.error:
            pass  # Ignore contour errors

        # Return dictionary of all features
        return {
            "area": area,
            "aspect_ratio": aspect_ratio,
            "centroid_x": centroid_x,
            "centroid_y": centroid_y,
            "perimeter": perimeter,
            "larger_dim": larger_dim,
            "smaller_dim": smaller_dim,
            "angle": angle,  # Angle from minAreaRect
            "min_rect_vertices": min_rect_vertices,  # Vertices from minAreaRect
            "bbox": bbox  # Axis-aligned bounding box [x1, y1, x2, y2]
        }

    def _filter_edge_masks(self, masks: List[np.ndarray], filter_shape: Tuple[int, int], edge_threshold: int) -> List[
        np.ndarray]:
        """
        Filters out masks whose bounding boxes are too close to the image edges.

        Args:
            masks (List[np.ndarray]): List of input masks.
            filter_shape (Tuple[int, int]): The shape (height, width) of the image.
            edge_threshold (int): Minimum pixel distance allowed from any edge.

        Returns:
            List[np.ndarray]: List of masks that are not too close to the edges.
        """
        filter_height, filter_width = filter_shape
        filtered_masks = []
        for i, mask in enumerate(masks):
            if not isinstance(mask, np.ndarray) or mask.ndim != 2: continue  # Skip invalid masks
            y_indices, x_indices = np.where(mask > 0)
            if len(y_indices) == 0: continue  # Skip empty masks

            # Get bounding box
            x1, x2 = np.min(x_indices), np.max(x_indices)
            y1, y2 = np.min(y_indices), np.max(y_indices)

            # Check proximity to edges
            is_near_edge = (x1 < edge_threshold or
                            x2 >= filter_width - edge_threshold or
                            y1 < edge_threshold or
                            y2 >= filter_height - edge_threshold)

            if not is_near_edge:
                filtered_masks.append(mask)  # Keep mask if not near edge

        return filtered_masks

    def test_masks(self, masks: List[np.ndarray], filter_shape: Tuple[int, int], max_masks_to_show: int = None,
                   edge_threshold: int = 5, sort_by_area: bool = True) -> List[Dict[str, Any]]:
        """
        Processes masks for testing/visualization purposes.
        Performs edge filtering, extracts features, and formats results.
        Does NOT perform classification or evaluation against the config.

        Args:
            masks (List[np.ndarray]): List of input masks.
            filter_shape (Tuple[int, int]): Image shape (height, width).
            max_masks_to_show (Optional[int]): Maximum number of masks to return (sorted by area if applicable).
            edge_threshold (int): Threshold for edge filtering.
            sort_by_area (bool): If True, sorts the results by mask area (descending).

        Returns:
            List[Dict[str, Any]]: List of dictionaries, each containing 'mask', 'features',
                                  'min_rect_vertices' (as list), and 'labels' for visualization.
        """
        # 1. Filter masks near edges
        valid_masks = self._filter_edge_masks(masks, filter_shape, edge_threshold)
        if not valid_masks: return []

        # 2. Extract features for remaining masks
        mask_features_list = []
        for mask in valid_masks:
            features = self.extract_features(mask)
            if features:
                mask_features_list.append({"mask": mask, "features": features})
        if not mask_features_list: return []

        # 3. Sort by area if requested
        if sort_by_area:
            mask_features_list.sort(key=lambda x: x["features"]["area"], reverse=True)

        # 4. Limit number of masks if requested
        if max_masks_to_show is not None and len(mask_features_list) > max_masks_to_show:
            mask_features_list = mask_features_list[:max_masks_to_show]

        # 5. Format results for visualization
        results = []
        for item in mask_features_list:
            mask = item["mask"]
            features = item["features"]
            # Get vertices and convert to list of lists for easier handling/JSON
            min_rect_vertices_np = features.get("min_rect_vertices")
            min_rect_vertices_list = min_rect_vertices_np.tolist() if isinstance(min_rect_vertices_np,
                                                                                 np.ndarray) else [[0,
                                                                                                    0]] * 4  # Fallback

            # Prepare basic labels for visualization
            labels = [
                f"Area: {features.get('area', 0):.0f}",
                f"AR: {features.get('aspect_ratio', 0):.2f}",
                f"Angle: {features.get('angle', 0):.1f}"
            ]
            results.append({
                "mask": mask,
                "features": features,
                "min_rect_vertices": min_rect_vertices_list,  # Use the list version
                "labels": labels
            })
        return results

    def classify_masks(self,
                       masks: List[np.ndarray],
                       filter_shape: Tuple[int, int],
                       edge_threshold: int,
                       enable_mask_iou_filter: bool = True,
                       iou_threshold: float = 0.9,
                       enable_relative_position_check: bool = True,
                       relative_position_pairs_to_check: Optional[List[str]] = None,
                       enable_containment_check: bool = True,
                       containment_reference_type: str = "bezel",
                       containment_target_type: str = "stamped_mark",
                       enable_bbox_nms: bool = True,
                       bbox_nms_iou_threshold: float = 0.5,
                       bbox_nms_target_types: Optional[List[str]] = None
                       ) -> Dict[str, List[Dict]]:
        """
        Performs the full sequence of classification and filtering steps on input masks.

        Workflow Steps:
        1. Edge Filter: Removes masks too close to image borders.
        2. Mask IoU Filter: (Optional) Removes highly overlapping masks (pixel-based).
        3. Feature Classification: Assigns a tentative type based on feature ranges.
        4. BBox NMS Filter: (If enabled) Removes overlapping bounding boxes for specified types.
        5. Distance Filter: Checks pairwise distances against constraints.
        6. Containment Filter: (If enabled) Checks if target centroid is within ref bbox X or Y range.
        7. Relative Position Filter: (If enabled) Checks relative positions against constraints.
        """
        stage_start_time = time.time()
        print("[Checker][classify_masks] Starting integrated classification...")
        if bbox_nms_target_types is None:
            bbox_nms_target_types = ["stamped_mark"]

        # --- 1. Edge Filtering ---
        t0 = time.time()
        edge_filtered_masks = self._filter_edge_masks(masks, filter_shape, edge_threshold)
        t1 = time.time()
        print(f"[TIME] Edge Filter: {t1 - t0:.4f}s")
        if not edge_filtered_masks:
            print("[Checker][classify_masks] No masks after edge filtering.")
            return {r['type']: [] for r in self.classification_rules} if self.classification_rules else {}
        print(f"[Checker][classify_masks] Edge filtering complete ({len(edge_filtered_masks)} masks remain).")

        # --- 2. Mask IoU Filtering (Pixel-based) ---
        t0 = time.time()
        iou_filtered_masks = []
        if enable_mask_iou_filter:
            print(f"[Checker][classify_masks] Applying Mask IoU filter (Threshold: {iou_threshold:.2f})...")
            num_initial_masks_iou = len(edge_filtered_masks)
            if num_initial_masks_iou <= 1:
                iou_filtered_masks = edge_filtered_masks
            else:
                mask_areas = []
                valid_indices_for_iou = []
                for idx, m in enumerate(edge_filtered_masks):
                    area = np.sum(m.astype(bool))
                    if area > 0:
                        mask_areas.append(area)
                        valid_indices_for_iou.append(idx)

                if len(valid_indices_for_iou) <= 1:
                    iou_filtered_masks = [edge_filtered_masks[i] for i in valid_indices_for_iou]
                else:
                    num_valid_masks = len(valid_indices_for_iou)
                    to_remove_original_indices = set()
                    valid_masks_for_compare = [edge_filtered_masks[i] for i in valid_indices_for_iou]

                    for i_valid in range(num_valid_masks):
                        original_idx_i = valid_indices_for_iou[i_valid]
                        if original_idx_i in to_remove_original_indices: continue

                        for j_valid in range(i_valid + 1, num_valid_masks):
                            original_idx_j = valid_indices_for_iou[j_valid]
                            if original_idx_j in to_remove_original_indices: continue

                            mask_i = valid_masks_for_compare[i_valid]
                            mask_j = valid_masks_for_compare[j_valid]
                            iou = calculate_iou(mask_i.astype(bool), mask_j.astype(bool))

                            if iou > iou_threshold:
                                if mask_areas[i_valid] >= mask_areas[j_valid]:
                                    to_remove_original_indices.add(original_idx_j)
                                else:
                                    to_remove_original_indices.add(original_idx_i)
                                    break

                    iou_filtered_masks = [edge_filtered_masks[i] for i in valid_indices_for_iou if
                                          i not in to_remove_original_indices]

            num_removed_iou = num_initial_masks_iou - len(iou_filtered_masks)
            print(
                f"[Checker][classify_masks] Mask IoU filtering complete ({num_removed_iou} removed, {len(iou_filtered_masks)} remain).")
        else:
            print("[Checker][classify_masks] Mask IoU filter explicitly disabled. Skipping.")
            iou_filtered_masks = edge_filtered_masks

        t1 = time.time()
        print(f"[TIME] Mask IoU Filter: {t1 - t0:.4f}s")
        if not iou_filtered_masks:
            print("[Checker][classify_masks] No masks after Mask IoU filtering step.")
            return {r['type']: [] for r in self.classification_rules} if self.classification_rules else {}

        # --- 3. Initial Feature Classification ---
        t0 = time.time()
        print("[Checker][classify_masks] Performing initial feature classification...")
        if not self.classification_rules:
            print("[Error][classify_masks] No classification rules defined.")
            return {}

        classified_by_features: Dict[str, List[Dict]] = {rule['type']: [] for rule in self.classification_rules}
        feature_classified_list: List[Dict] = []
        unclassified_count = 0

        for mask in iou_filtered_masks:
            features = self.extract_features(mask)
            if not features: continue

            classified_flag = False
            for rule in self.classification_rules:
                obj_type = rule['type']
                ranges = rule['ranges']
                match = True
                if not isinstance(ranges, dict):
                    match = False
                else:
                    for feature_key, range_tuple in ranges.items():
                        if feature_key in ['angle', 'min_rect_vertices', 'bbox'] and feature_key not in ranges: continue
                        if not isinstance(range_tuple, (tuple, list)) or len(range_tuple) != 2:
                            match = False
                            break
                        min_val, max_val = range_tuple
                        feature_value = features.get(feature_key)
                        if feature_value is None or not (min_val <= feature_value <= max_val):
                            match = False
                            break
                if match:
                    mask_info = {"features": features, "mask": mask, "type": obj_type}
                    classified_by_features[obj_type].append(mask_info)
                    feature_classified_list.append(mask_info)
                    classified_flag = True
                    break
            if not classified_flag:
                unclassified_count += 1

        num_feature_classified = len(feature_classified_list)
        t1 = time.time()
        print(
            f"[Checker][classify_masks] Feature classification done. Classified: { {k: len(v) for k, v in classified_by_features.items()} }, Unclassified: {unclassified_count}")
        print(f"[TIME] Feature Classification: {t1 - t0:.4f}s")
        if num_feature_classified == 0:
            print("[Checker][classify_masks] No masks passed feature classification.")
            return classified_by_features

        # --- 4. BBox NMS Filter (Bounding Box based) ---
        t0 = time.time()
        passed_bbox_nms_filter: Dict[str, List[Dict]] = {}
        feature_passed_bbox_nms_list: List[Dict] = []
        objects_removed_bbox_nms = 0

        if not enable_bbox_nms:
            print("[Checker][classify_masks] BBox NMS explicitly disabled. Skipping filter.")
            passed_bbox_nms_filter = classified_by_features
            feature_passed_bbox_nms_list = feature_classified_list
        else:
            print(
                f"[Checker][classify_masks] Applying BBox NMS filter (IoU Threshold: {bbox_nms_iou_threshold:.2f}, Targets: {bbox_nms_target_types})...")
            for obj_type, masks_info_list in classified_by_features.items():
                if obj_type not in bbox_nms_target_types:
                    passed_bbox_nms_filter[obj_type] = masks_info_list
                    feature_passed_bbox_nms_list.extend(masks_info_list)
                else:
                    if len(masks_info_list) <= 1:
                        if masks_info_list:
                            passed_bbox_nms_filter[obj_type] = masks_info_list
                            feature_passed_bbox_nms_list.extend(masks_info_list)
                        else:
                            passed_bbox_nms_filter[obj_type] = []
                        continue

                    masks_info_list.sort(key=lambda info: info.get("features", {}).get("area", 0), reverse=True)

                    kept_indices = []
                    suppressed_indices = [False] * len(masks_info_list)

                    for i in range(len(masks_info_list)):
                        if suppressed_indices[i]: continue

                        kept_indices.append(i)
                        bbox_i = masks_info_list[i].get("features", {}).get("bbox")
                        if not bbox_i: continue

                        for j in range(i + 1, len(masks_info_list)):
                            if suppressed_indices[j]: continue

                            bbox_j = masks_info_list[j].get("features", {}).get("bbox")
                            if not bbox_j: continue

                            iou = calculate_bbox_iou(bbox_i, bbox_j)

                            if iou > bbox_nms_iou_threshold:
                                suppressed_indices[j] = True
                                objects_removed_bbox_nms += 1

                    kept_masks = [masks_info_list[k] for k in kept_indices]
                    passed_bbox_nms_filter[obj_type] = kept_masks
                    feature_passed_bbox_nms_list.extend(kept_masks)

            print(f"[Checker][classify_masks] BBox NMS filter applied. {objects_removed_bbox_nms} removed.")
        t1 = time.time()
        print(f"[TIME] BBox NMS Filter: {t1 - t0:.4f}s")
        if not feature_passed_bbox_nms_list:
            print("[Checker][classify_masks] No masks remaining after BBox NMS filter.")
            return passed_bbox_nms_filter

        # --- 5. Strict Distance Filtering ---
        t0 = time.time()
        print("[Checker][classify_masks] Applying strict distance constraint filter...")
        if not self.distance_constraints:
            print("[Checker][classify_masks] No distance constraints. Skipping distance filter.")
            passed_distance_filter = passed_bbox_nms_filter
            feature_passed_distance_list = feature_passed_bbox_nms_list
        elif not feature_passed_bbox_nms_list:
            print("[Checker][classify_masks] No masks remaining after previous filter for distance check.")
            passed_distance_filter = passed_bbox_nms_filter
            feature_passed_distance_list = feature_passed_bbox_nms_list
        else:
            passed_distance_filter: Dict[str, List[Dict]] = {rule['type']: [] for rule in self.classification_rules}
            feature_passed_distance_list: List[Dict] = []
            objects_failed_distance_count = 0
            first_distance_failure_reason = "All objects satisfy applicable distance constraints"

            for obj1_info in feature_passed_bbox_nms_list:
                obj1_type = obj1_info['type']
                obj1_features = obj1_info.get("features", {})
                obj1_passes_all_constraints = True
                relevant_constraints = {}
                constraint_check_possible = True

                for pair_key, constraint_data in self.distance_constraints.items():
                    obj_types_in_pair = pair_key.split('-')
                    if obj1_type in obj_types_in_pair:
                        dist_range = constraint_data.get("range")
                        if not isinstance(dist_range, (tuple, list)) or len(dist_range) != 2:
                            obj1_passes_all_constraints = False
                            failure_reason = f"Dist_NG: Invalid range format '{pair_key}'"
                            if objects_failed_distance_count == 0: first_distance_failure_reason = failure_reason
                            constraint_check_possible = False
                            break
                        relevant_constraints[pair_key] = {'data': constraint_data, 'satisfied': False}

                if not constraint_check_possible:
                    objects_failed_distance_count += 1
                    continue

                if relevant_constraints:
                    for pair_key, status_info in relevant_constraints.items():
                        if not obj1_passes_all_constraints: break

                        constraint_data = status_info['data']
                        min_dist, max_dist = constraint_data["range"]
                        obj_types_in_pair = pair_key.split('-')
                        obj2_type = next(t for t in obj_types_in_pair if t != obj1_type)
                        obj2_list = passed_bbox_nms_filter.get(obj2_type, [])

                        if not obj2_list:
                            obj1_passes_all_constraints = False
                            failure_reason = f"Dist_NG: {obj1_type} failed '{pair_key}' - no post-NMS '{obj2_type}' found."
                            if objects_failed_distance_count == 0: first_distance_failure_reason = failure_reason
                            break

                        found_satisfying_pair = False
                        for obj2_info in obj2_list:
                            if obj1_info is obj2_info: continue

                            f1 = obj1_info.get("features")
                            f2 = obj2_info.get("features")
                            if not f1 or not f2: continue

                            c1x, c1y = f1.get("centroid_x"), f1.get("centroid_y")
                            c2x, c2y = f2.get("centroid_x"), f2.get("centroid_y")

                            if None not in [c1x, c1y, c2x, c2y]:
                                try:
                                    dist = math.sqrt((c2x - c1x) ** 2 + (c2y - c1y) ** 2)
                                    if min_dist <= dist <= max_dist:
                                        status_info['satisfied'] = True
                                        found_satisfying_pair = True
                                        break
                                except Exception:
                                    obj1_passes_all_constraints = False
                                    failure_reason = f"Dist_NG: Error calc dist '{pair_key}'"
                                    if objects_failed_distance_count == 0: first_distance_failure_reason = failure_reason
                                    break

                        if not obj1_passes_all_constraints: break

                        if not found_satisfying_pair:
                            obj1_passes_all_constraints = False
                            failure_reason = f"Dist_NG: {obj1_type} failed '{pair_key}' - no partner in range."
                            if objects_failed_distance_count == 0: first_distance_failure_reason = failure_reason
                            break

                if obj1_passes_all_constraints:
                    passed_distance_filter[obj1_type].append(obj1_info)
                    feature_passed_distance_list.append(obj1_info)
                else:
                    objects_failed_distance_count += 1

            num_passed_distance = len(feature_passed_distance_list)
            print(
                f"[Checker][classify_masks] Distance filter applied. {objects_failed_distance_count} removed, {num_passed_distance} remain.")
            if num_passed_distance == 0 and len(feature_passed_bbox_nms_list) > 0:
                print("[Checker][classify_masks] No masks passed distance filter.")
                if objects_failed_distance_count > 0: print(f"  Reason: {first_distance_failure_reason}")
                return passed_distance_filter
        t1 = time.time()
        print(f"[TIME] Distance Filter: {t1 - t0:.4f}s")

        # --- 6. Centroid Containment Filter ---
        t0 = time.time()
        passed_containment_filter: Dict[str, List[Dict]] = {rule['type']: [] for rule in self.classification_rules}
        feature_passed_containment_list: List[Dict] = []
        objects_failed_containment_count = 0

        if not enable_containment_check:
            print("[Checker][classify_masks] Centroid containment check explicitly disabled. Skipping filter.")
            passed_containment_filter = passed_distance_filter
            feature_passed_containment_list = feature_passed_distance_list
        elif not feature_passed_distance_list:
            print("[Checker][classify_masks] No masks remaining after distance filter for containment check.")
            passed_containment_filter = passed_distance_filter
            feature_passed_containment_list = feature_passed_distance_list
        else:
            print(
                f"[Checker][classify_masks] Applying centroid containment filter (Target: '{containment_target_type}' inside '{containment_reference_type}' BBox X OR Y range)...")

            reference_objects = passed_distance_filter.get(containment_reference_type, [])
            reference_bbox = None
            if len(reference_objects) == 1:
                ref_features = reference_objects[0].get("features", {})
                reference_bbox = ref_features.get("bbox")
                if not isinstance(reference_bbox, list) or len(reference_bbox) != 4:
                    print(
                        f"[Warning][Containment] Invalid bbox for reference '{containment_reference_type}'. Cannot perform check.")
                    reference_bbox = None
            elif len(reference_objects) == 0:
                print(
                    f"[Warning][Containment] Reference '{containment_reference_type}' not found after previous filters. Cannot perform check.")
            else:
                print(
                    f"[Warning][Containment] Multiple ({len(reference_objects)}) references '{containment_reference_type}' found. Cannot perform check.")

            for obj_info in feature_passed_distance_list:
                obj_type = obj_info['type']
                obj_features = obj_info.get("features", {})

                if obj_type == containment_target_type and reference_bbox is not None:
                    target_cx = obj_features.get("centroid_x")
                    target_cy = obj_features.get("centroid_y")

                    if target_cx is not None and target_cy is not None:
                        ref_x1, ref_y1, ref_x2, ref_y2 = reference_bbox
                        is_within_x = (ref_x1 <= target_cx <= ref_x2)
                        is_within_y = (ref_y1 <= target_cy <= ref_y2)

                        if is_within_x or is_within_y:
                            passed_containment_filter[obj_type].append(obj_info)
                            feature_passed_containment_list.append(obj_info)
                        else:
                            objects_failed_containment_count += 1
                    else:
                        print(f"[Warning][Containment] Missing centroid for target '{obj_type}'. Passing filter.")
                        passed_containment_filter[obj_type].append(obj_info)
                        feature_passed_containment_list.append(obj_info)
                else:
                    passed_containment_filter[obj_type].append(obj_info)
                    feature_passed_containment_list.append(obj_info)

            num_passed_containment = len(feature_passed_containment_list)
            print(
                f"[Checker][classify_masks] BBox OR Containment filter applied. {objects_failed_containment_count} removed, {num_passed_containment} remain.")
            if num_passed_containment == 0 and len(feature_passed_distance_list) > 0:
                print("[Checker][classify_masks] No masks passed BBox OR containment filter.")
        t1 = time.time()
        print(f"[TIME] Containment Filter: {t1 - t0:.4f}s")

        # --- 7. Relative Position Filtering ---
        t0 = time.time()
        if not enable_relative_position_check:
            print("[Checker][classify_masks] Relative position check explicitly disabled. Skipping filter.")
            final_classification = passed_containment_filter
        elif not self.relative_position_constraints:
            print("[Checker][classify_masks] No relative position constraints defined. Skipping filter.")
            final_classification = passed_containment_filter
        elif not feature_passed_containment_list:
            print("[Checker][classify_masks] No masks remaining after containment filter for relative position check.")
            final_classification = passed_containment_filter
        else:
            print("[Checker][classify_masks] Applying relative position constraint filter...")

            check_pairs_set = None
            if relative_position_pairs_to_check is not None:
                check_pairs_set = set("-".join(sorted(p.split('-'))) for p in relative_position_pairs_to_check)
                print(f"  - Only checking pairs: {check_pairs_set}")

            final_classification: Dict[str, List[Dict]] = {rule['type']: [] for rule in self.classification_rules}
            objects_failed_relpos_count = 0
            first_relpos_failure_reason = "All objects satisfy applicable relative position constraints"

            for obj1_info in feature_passed_containment_list:
                obj1_type = obj1_info['type']
                obj1_features = obj1_info.get("features", {})
                obj1_passes_all_relpos = True
                relevant_relpos_constraints = {}
                constraint_check_possible = True

                for pair_key, constraint_data in self.relative_position_constraints.items():
                    obj_types_in_pair = pair_key.split('-')
                    if obj1_type in obj_types_in_pair:
                        sorted_pair_key = "-".join(sorted(obj_types_in_pair))
                        if check_pairs_set is not None and sorted_pair_key not in check_pairs_set:
                            continue

                        dx_range = constraint_data.get("dx_range")
                        dy_range = constraint_data.get("dy_range")
                        if not isinstance(dx_range, tuple) or not isinstance(dy_range, tuple):
                            obj1_passes_all_relpos = False
                            failure_reason = f"RelPos_NG: Invalid range format '{pair_key}'"
                            if objects_failed_relpos_count == 0: first_relpos_failure_reason = failure_reason
                            constraint_check_possible = False
                            break
                        relevant_relpos_constraints[pair_key] = {'data': constraint_data, 'satisfied': False}

                if not constraint_check_possible:
                    objects_failed_relpos_count += 1
                    continue

                if relevant_relpos_constraints:
                    obj1_angle_deg = obj1_features.get("angle")
                    obj1_cx = obj1_features.get("centroid_x")
                    obj1_cy = obj1_features.get("centroid_y")

                    if obj1_angle_deg is None or obj1_cx is None or obj1_cy is None:
                        obj1_passes_all_relpos = False
                        failure_reason = f"RelPos_NG: Missing angle/centroid for {obj1_type}"
                        if objects_failed_relpos_count == 0: first_relpos_failure_reason = failure_reason
                    else:
                        obj1_angle_rad = math.radians(obj1_angle_deg)
                        cos_a = math.cos(-obj1_angle_rad)
                        sin_a = math.sin(-obj1_angle_rad)

                        for pair_key, status_info in relevant_relpos_constraints.items():
                            if not obj1_passes_all_relpos: break

                            constraint_data = status_info['data']
                            min_dx, max_dx = constraint_data["dx_range"]
                            min_dy, max_dy = constraint_data["dy_range"]
                            obj_types_in_pair = pair_key.split('-')

                            if obj_types_in_pair[0] == obj_types_in_pair[1]:
                                obj2_type = obj1_type
                            else:
                                other_types = [t for t in obj_types_in_pair if t != obj1_type]
                                if not other_types:
                                    obj1_passes_all_relpos = False
                                    failure_reason = f"RelPos_NG: Invalid pair key '{pair_key}'"
                                    if objects_failed_relpos_count == 0: first_relpos_failure_reason = failure_reason
                                    break
                                obj2_type = other_types[0]

                            obj2_list = passed_containment_filter.get(obj2_type, [])

                            if not obj2_list:
                                obj1_passes_all_relpos = False
                                failure_reason = f"RelPos_NG: {obj1_type} failed '{pair_key}' - no post-containment '{obj2_type}' found."
                                if objects_failed_relpos_count == 0: first_relpos_failure_reason = failure_reason
                                break

                            found_satisfying_pair = False
                            for obj2_info in obj2_list:
                                if obj1_info is obj2_info: continue

                                f2 = obj2_info.get("features")
                                if not f2: continue

                                obj2_cx = f2.get("centroid_x")
                                obj2_cy = f2.get("centroid_y")

                                if obj2_cx is not None and obj2_cy is not None:
                                    dx = obj2_cx - obj1_cx
                                    dy = obj2_cy - obj1_cy
                                    dx_rel = dx * cos_a - dy * sin_a
                                    dy_rel = dx * sin_a + dy * cos_a

                                    if (min_dx <= dx_rel <= max_dx) and (min_dy <= dy_rel <= max_dy):
                                        status_info['satisfied'] = True
                                        found_satisfying_pair = True
                                        break
                                else:
                                    print(f"[Warning][RelPos] Missing centroid for partner {obj2_type}.")

                            if not found_satisfying_pair:
                                obj1_passes_all_relpos = False
                                failure_reason = f"RelPos_NG: {obj1_type} failed '{pair_key}' - no partner in rel pos range."
                                if objects_failed_relpos_count == 0: first_relpos_failure_reason = failure_reason
                                break

                if obj1_passes_all_relpos:
                    final_classification[obj1_type].append(obj1_info)
                else:
                    objects_failed_relpos_count += 1

            num_passed_all = sum(len(v) for v in final_classification.values())
            print(
                f"[Checker][classify_masks] Relative position filter applied. {objects_failed_relpos_count} removed, {num_passed_all} remain.")
            if num_passed_all == 0 and len(feature_passed_containment_list) > 0:
                print("[Checker][classify_masks] No masks passed relative position filter.")
                if objects_failed_relpos_count > 0: print(f"  Reason: {first_relpos_failure_reason}")
        t1 = time.time()
        print(f"[TIME] Relative Position Filter: {t1 - t0:.4f}s")

        total_classify_time = time.time() - stage_start_time
        print(f"[TIME] Total classify_masks duration: {total_classify_time:.4f}s")
        print(
            f"[Checker][classify_masks] Final classification counts after all filters: { {k: len(v) for k, v in final_classification.items()} }")
        return final_classification

    # --- END classify_masks METHOD ---

    def check_overlaps(self, classified: Dict[str, List[Dict]]) -> Tuple[bool, str]:
        """
        Detects forbidden pixel overlaps between pairs of objects based on overlap rules.

        Args:
            classified (Dict[str, List[Dict]]): Dictionary of objects that passed
                                                all previous filtering steps.

        Returns:
            Tuple[bool, str]: (True, reason) if no forbidden overlaps found,
                              (False, reason) if a forbidden overlap is detected.
        """
        if not self.overlap_rules: return True, "No overlap rules defined"

        # Iterate through each overlap rule defined in the configuration
        for rule in self.overlap_rules:
            obj_types = rule.get("objects")  # List of two object types (e.g., ["bezel", "copper_mark"])
            mode = rule.get("mode", "absolute").lower()  # "absolute" or "ratio"
            threshold = rule.get("threshold", 0.0)  # Used only for "ratio" mode

            # Validate rule format
            if not obj_types or len(obj_types) != 2:
                print(f"[Warning] Invalid 'objects' list in overlap rule: {rule}. Skipping.")
                continue

            obj1_type, obj2_type = obj_types[0], obj_types[1]
            # Get the lists of classified objects for these types
            obj1_list = classified.get(obj1_type, [])
            obj2_list = classified.get(obj2_type, [])

            # No need to check if one or both types have no objects
            if not obj1_list or not obj2_list: continue

            # Compare each object of type 1 with each object of type 2
            for o1_idx, o1 in enumerate(obj1_list):
                # If checking overlaps within the same type, avoid self-comparison and duplicates
                start_idx = o1_idx + 1 if obj1_type == obj2_type else 0
                for o2_idx in range(start_idx, len(obj2_list)):
                    o2 = obj2_list[o2_idx]

                    mask1 = o1.get("mask")
                    mask2 = o2.get("mask")
                    if mask1 is None or mask2 is None:
                        print(f"[Warning] Missing mask for overlap check between {obj1_type} and {obj2_type}.")
                        continue  # Skip if mask data is missing

                    # Ensure masks are boolean for bitwise operations
                    mask1_bool = mask1.astype(bool) if mask1.dtype != bool else mask1
                    mask2_bool = mask2.astype(bool) if mask2.dtype != bool else mask2

                    # Calculate intersection (pixels common to both masks)
                    intersection = np.sum(mask1_bool & mask2_bool)

                    # Apply rule based on mode
                    if mode == "absolute":
                        # Fail if *any* intersection exists
                        if intersection > 0:
                            reason = f"Overlap_NG: Absolute overlap detected between {obj1_type} and {obj2_type}"
                            return False, reason
                    elif mode == "ratio":
                        # Calculate union and ratio
                        union = np.sum(mask1_bool | mask2_bool)
                        overlap_ratio = intersection / union if union > 0 else 0.0
                        # Fail if ratio exceeds threshold
                        if overlap_ratio > threshold:
                            reason = f"Overlap_NG: Ratio between {obj1_type} & {obj2_type} ({overlap_ratio:.3f}) > threshold {threshold:.3f}"
                            return False, reason
                    else:  # Default to absolute if mode is unrecognized
                        if intersection > 0:
                            reason = f"Overlap_NG: Absolute overlap detected between {obj1_type} and {obj2_type}"
                            return False, reason

        # If loop completes without finding forbidden overlaps
        return True, "No excessive overlaps detected"

    def evaluate(self,
                 masks: List[np.ndarray],
                 filter_shape: Tuple[int, int],
                 edge_threshold: int = 5,
                 enable_mask_iou_filter: bool = True,
                 iou_threshold: float = 0.9,
                 enable_relative_position_check: bool = True,
                 relative_position_pairs_to_check: Optional[List[str]] = None,
                 enable_containment_check: bool = True,
                 containment_reference_type: str = "bezel",
                 containment_target_type: str = "stamped_mark",
                 enable_bbox_nms: bool = True,
                 bbox_nms_iou_threshold: float = 0.5,
                 bbox_nms_target_types: Optional[List[str]] = None,
                 # --- NEW PARAMETER ---
                 enable_pwb_check: bool = True # Flag to indicate if PWB check is globally enabled
                 ) -> Tuple[bool, str, Dict[str, List[Dict]]]:
        """
        Performs the complete evaluation process on a list of input masks.
        If enable_pwb_check is False, the count check for 'stamped_mark' is skipped.

        Steps:
        1. Calls `classify_masks` to perform all filtering.
        2. Performs a Count Check (skipping 'stamped_mark' if PWB check is disabled).
        3. Performs an Overlap Check.

        Args:
            # ... (other args remain the same) ...
            enable_pwb_check (bool): If False, skip count check for 'stamped_mark'.

        Returns:
            Tuple[bool, str, Dict[str, List[Dict]]]:
                - final_ok (bool): True if all checks passed, False otherwise.
                - final_reason (str): Explanation of the evaluation result or error.
                - final_classified_masks (Dict): Dictionary of masks that passed all checks.
        """
        eval_start_time = time.time()
        print("[Checker] Starting evaluation...")
        final_reason = "Evaluation not completed"
        final_classified_masks: Dict[str, List[Dict]] = {rule['type']: [] for rule in
                                                         self.classification_rules} if self.classification_rules else {}

        # --- 1. Integrated Classification & Filtering ---
        t0_classify = time.time()
        try:
            # Call the method that performs steps 1-7 of the filtering workflow
            final_classified_masks = self.classify_masks(
                masks, filter_shape, edge_threshold,
                enable_mask_iou_filter=enable_mask_iou_filter,
                iou_threshold=iou_threshold,
                enable_relative_position_check=enable_relative_position_check,
                relative_position_pairs_to_check=relative_position_pairs_to_check,
                enable_containment_check=enable_containment_check,
                containment_reference_type=containment_reference_type,
                containment_target_type=containment_target_type,
                enable_bbox_nms=enable_bbox_nms,
                bbox_nms_iou_threshold=bbox_nms_iou_threshold,
                bbox_nms_target_types=bbox_nms_target_types
            )
            num_final_classified = sum(len(v) for v in final_classified_masks.values())
            t1_classify = time.time()
            print(f"[TIME] Integrated Classification (classify_masks call): {t1_classify - t0_classify:.4f}s")

            if num_final_classified == 0 and len(masks) > 0:
                final_reason = "Eval_NG: No masks passed the combined classification and filtering steps."
                print(f"[Checker] {final_reason}")
                eval_duration = time.time() - eval_start_time
                print(f"[TIME] Total evaluate duration (early exit): {eval_duration:.4f}s")
                return False, final_reason, final_classified_masks

            print(f"[Checker] Integrated classification/filtering complete ({num_final_classified} masks remain).")

        except Exception as e:
            t1_classify = time.time()
            final_reason = f"Eval_NG: Unexpected error during integrated classification: {e}"
            print(f"[Checker] {final_reason}\n{traceback.format_exc()}")
            print(f"[TIME] Integrated Classification (Failed): {t1_classify - t0_classify:.4f}s")
            eval_duration = time.time() - eval_start_time
            print(f"[TIME] Total evaluate duration (error): {eval_duration:.4f}s")
            return False, final_reason, final_classified_masks
        # --- End Integrated Classification ---

        # --- 2. Count Check (MODIFIED) ---
        t0_count = time.time()
        print("[Checker] Performing count check...")
        count_ok = True
        count_reason_parts = []
        stamped_mark_skipped = False # Flag to track if stamped_mark count was skipped
        if not self.classification_rules:
            print("[Warning] No classification rules defined for count check.")
        else:
            for rule in self.classification_rules:
                obj_type = rule['type']
                expected_eval_count = rule['expected_count']

                # --- MODIFICATION: Skip stamped_mark count if PWB check is disabled ---
                if obj_type == "stamped_mark" and not enable_pwb_check:
                    print(f"[Info][Count Check] Skipping count check for '{obj_type}' because PWB check is disabled.")
                    stamped_mark_skipped = True
                    continue # Skip to the next rule
                # --- End Modification ---

                found_count = len(final_classified_masks.get(obj_type, []))
                if found_count != expected_eval_count:
                    count_ok = False
                    count_reason_parts.append(
                        f"Count_NG(Cfg): Expected {expected_eval_count} '{obj_type}', found {found_count}")

        t1_count = time.time()
        print(f"[TIME] Count Check: {t1_count - t0_count:.4f}s")

        if not count_ok:
            final_reason = "Eval_NG: " + "; ".join(count_reason_parts)
            print(f"[Checker] {final_reason}")
            eval_duration = time.time() - eval_start_time
            print(f"[TIME] Total evaluate duration (count fail): {eval_duration:.4f}s")
            return False, final_reason, final_classified_masks

        print("[Checker] Count check passed." + (" (Stamped Mark skipped)" if stamped_mark_skipped else ""))
        # --- End Count Check ---

        # --- 3. Overlap Check ---
        t0_overlap = time.time()
        print("[Checker] Performing overlap check...")
        overlap_ok, overlap_reason = self.check_overlaps(final_classified_masks)
        t1_overlap = time.time()
        print(f"[TIME] Overlap Check: {t1_overlap - t0_overlap:.4f}s")

        if not overlap_ok:
            final_reason = f"Eval_NG: {overlap_reason}"
            print(f"[Checker] {final_reason}")
            eval_duration = time.time() - eval_start_time
            print(f"[TIME] Total evaluate duration (overlap fail): {eval_duration:.4f}s")
            return False, final_reason, final_classified_masks

        print(f"[Checker] Overlap check passed ({overlap_reason}).")
        # --- End Overlap Check ---

        # If all checks passed
        final_reason = "OK: All checks passed (Integrated Filters, Count"
        if stamped_mark_skipped:
            final_reason += " [Stamped Mark Skipped]"
        final_reason += ", Overlap)"

        eval_duration = time.time() - eval_start_time
        print(f"[Checker] Evaluation Result: {final_reason}")
        print(f"[TIME] Total evaluate duration: {eval_duration:.4f}s")
        return True, final_reason, final_classified_masks

    # --- END evaluate METHOD ---


    # --- UPDATED METHOD: check_internal_geometry ---

    # --- UPDATED METHOD: check_internal_geometry ---
    def check_internal_geometry(self,
                                target_object_info: Dict,
                                original_image: np.ndarray,
                                check_config: Dict,
                                # --- MODIFIED: Flag now controls preparation, not display ---
                                prepare_display_images: bool = False
                                ) -> Tuple[
        bool, str, Optional[float], Optional[float], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
        # --- MODIFIED: Return signature includes images ---
        """
        Performs an internal geometry check on a target object (e.g., PWB).
        Calculates effective mm/pixel based on calibration reference values.
        Adds an additional pixel offset before converting to millimeters.
        Finds the maximum height of continuous vertical runs of target pixels,
        prioritizing runs in the center of the image.
        Uses perspective warp size to determine if rotation is needed.
        Optionally applies morphological smoothing (closing).
        Returns intermediate images if prepare_display_images is True.
        """
        print(f"[Checker][InternalGeom] Starting check (Calculated Factor + Offset, Centered Max Column Height)...")
        start_geom_time = time.time()

        # Initialize return images to None
        cropped_deskewed_for_display = None
        processed_binary_for_display = None
        processed_binary_annotated = None  # Annotated binary image

        # --- Input Validation and Config Extraction ---
        try:
            if not target_object_info or "features" not in target_object_info:
                return False, "InternalGeom_Error: Missing target object info or features.", None, None, None, None, None
            features = target_object_info["features"]
            min_rect_vertices_np = features.get("min_rect_vertices")
            if min_rect_vertices_np is None:
                return False, "InternalGeom_Error: Missing 'min_rect_vertices' in features.", None, None, None, None, None

            # Extract config parameters
            thresh = check_config.get("binarization_threshold")
            binary_inverted = check_config.get("binary_inverted", False)
            erode_iterations = check_config.get("erode_iterations", 0)
            dilate_iterations = check_config.get("dilate_iterations", 0)
            kernel_size_list = check_config.get("morph_kernel_size")
            enable_smoothing = check_config.get("enable_smoothing", False)
            min_distance_mm = check_config.get("min_distance_mm")
            max_distance_mm = check_config.get("max_distance_mm")
            calibration_ref_height_mm = check_config.get("calibration_ref_height_mm")
            calibration_ref_pixels = check_config.get("calibration_ref_pixels")
            additional_height_pixels = check_config.get("additional_height_pixels", 0)
            min_col_height_ratio = check_config.get("min_column_height_ratio", 0.5)
            col_edge_ignore_ratio = check_config.get("column_edge_ignore_ratio", 0.15)

            # Validate mandatory parameters (return includes image placeholders)
            if thresh is None: return False, "InternalGeom_Error: Missing 'binarization_threshold' in config.", None, None, None, None, None
            if not isinstance(binary_inverted,
                              bool): return False, "InternalGeom_Error: 'binary_inverted' must be boolean.", None, None, None, None, None
            if not isinstance(erode_iterations,
                              int) or erode_iterations < 0: return False, "InternalGeom_Error: Invalid 'erode_iterations'.", None, None, None, None, None
            if not isinstance(dilate_iterations,
                              int) or dilate_iterations < 0: return False, "InternalGeom_Error: Invalid 'dilate_iterations'.", None, None, None, None, None
            if kernel_size_list is None or len(
                    kernel_size_list) != 2: return False, "InternalGeom_Error: Invalid 'morph_kernel_size' in config.", None, None, None, None, None
            if not isinstance(enable_smoothing,
                              bool): return False, "InternalGeom_Error: 'enable_smoothing' must be boolean.", None, None, None, None, None
            if min_distance_mm is None: return False, "InternalGeom_Error: Missing 'min_distance_mm' in config.", None, None, None, None, None
            if max_distance_mm is None: return False, "InternalGeom_Error: Missing 'max_distance_mm' in config.", None, None, None, None, None
            if calibration_ref_height_mm is None: return False, "InternalGeom_Error: Missing 'calibration_ref_height_mm' in config.", None, None, None, None, None
            if calibration_ref_pixels is None: return False, "InternalGeom_Error: Missing 'calibration_ref_pixels' in config.", None, None, None, None, None
            if not isinstance(additional_height_pixels,
                              int) or additional_height_pixels < 0: return False, "InternalGeom_Error: Invalid 'additional_height_pixels' (must be non-negative integer).", None, None, None, None, None
            if not isinstance(min_col_height_ratio, (float, int)) or not (
                    0.0 <= min_col_height_ratio <= 1.0): return False, "InternalGeom_Error: Invalid 'min_column_height_ratio'.", None, None, None, None, None
            if not isinstance(col_edge_ignore_ratio, (float, int)) or not (
                    0.0 <= col_edge_ignore_ratio < 0.5): return False, "InternalGeom_Error: Invalid 'column_edge_ignore_ratio' (must be 0.0 to < 0.5).", None, None, None, None, None

            kernel_size = tuple(kernel_size_list)
            min_dist_mm = float(min_distance_mm)
            max_dist_mm = float(max_distance_mm)
            thresh = int(thresh)
            calibration_ref_height_mm = float(calibration_ref_height_mm)
            calibration_ref_pixels = float(calibration_ref_pixels)

            print(f"[Info][InternalGeom] Smoothing enabled: {enable_smoothing}")
            print(f"[Info][InternalGeom] Calibration Ref Height: {calibration_ref_height_mm:.5f} mm")
            print(f"[Info][InternalGeom] Calibration Ref Pixels: {calibration_ref_pixels:.1f}")
            print(f"[Info][InternalGeom] Additional Height Offset: {additional_height_pixels} pixels")

            # --- Calculate Effective Pixel Size from Calibration Values ---
            if calibration_ref_pixels <= 0:
                return False, "InternalGeom_Error: Calibration reference pixels must be positive.", None, None, None, None, None
            effective_mm_per_pixel = calibration_ref_height_mm / calibration_ref_pixels
            print(
                f"[Info][InternalGeom] Calculated Effective mm/pixel (for conversion): {effective_mm_per_pixel:.5f}")
            # --- End Calculation ---

        except (KeyError, TypeError, ValueError) as config_err:
            return False, f"InternalGeom_Error: Configuration error - {config_err}", None, None, None, None, None
        # --- End Validation ---

        measured_distance_pixels = None  # Raw measurement from image
        adjusted_distance_pixels = None  # Measurement + offset
        measured_distance_mm = None  # Final mm value
        max_height_info_overall = {'height': 0, 'x': -1, 'y_start': -1, 'y_end': -1}
        max_height_info_middle = {'height': 0, 'x': -1, 'y_start': -1, 'y_end': -1}

        try:
            # --- 1. Perspective Transform & Optional Rotation ---
            t0_crop = time.time()
            src_pts = np.array(min_rect_vertices_np, dtype=np.float32);
            width_rect_approx = np.linalg.norm(src_pts[0] - src_pts[1]);
            height_rect_approx = np.linalg.norm(src_pts[1] - src_pts[2]);
            dst_w = int(np.round(width_rect_approx));
            dst_h = int(np.round(height_rect_approx));
            dst_pts = np.array([[0, 0], [dst_w - 1, 0], [dst_w - 1, dst_h - 1], [0, dst_h - 1]], dtype=np.float32);
            rotate_crop = dst_h > (dst_w * 1.1);
            M = cv2.getPerspectiveTransform(src_pts, dst_pts);
            warp_w = dst_w + 2;
            warp_h = dst_h + 2;
            dst_pts_warp = np.array([[1, 1], [dst_w, 1], [dst_w, dst_h], [1, dst_h]], dtype=np.float32);
            M_warp = cv2.getPerspectiveTransform(src_pts, dst_pts_warp);
            cropped_deskewed = cv2.warpPerspective(original_image, M_warp, (warp_w, warp_h));
            dst_w, dst_h = warp_w, warp_h
            if rotate_crop: print(
                "[Info][InternalGeom] Vertical mark detected, rotating crop 90 degrees."); cropped_deskewed = cv2.rotate(
                cropped_deskewed, cv2.ROTATE_90_CLOCKWISE); dst_w, dst_h = dst_h, dst_w
            t1_crop = time.time();
            print(f"[TIME][InternalGeom] Cropping/Deskewing/Rotating: {t1_crop - t0_crop:.4f}s")
            if prepare_display_images: cropped_deskewed_for_display = cropped_deskewed.copy()  # Store for return

            # --- 2. Binarization ---
            t0_bin = time.time()
            if len(cropped_deskewed.shape) == 3:
                gray_cropped = cv2.cvtColor(cropped_deskewed, cv2.COLOR_BGR2GRAY)
            else:
                gray_cropped = cropped_deskewed
            thresh_type = cv2.THRESH_BINARY_INV if not binary_inverted else cv2.THRESH_BINARY
            _, binary_img = cv2.threshold(gray_cropped, thresh, 255, thresh_type)
            t1_bin = time.time();
            print(f"[TIME][InternalGeom] Binarization: {t1_bin - t0_bin:.4f}s")

            # --- 3. Optional Erode/Dilate ---
            processed_binary = binary_img.copy()  # Keep a copy before smoothing
            morph_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)
            if erode_iterations > 0: t0_erode = time.time(); processed_binary = cv2.erode(processed_binary,
                                                                                          morph_kernel,
                                                                                          iterations=erode_iterations); t1_erode = time.time(); print(
                f"[TIME][InternalGeom] Erosion ({erode_iterations} iter): {t1_erode - t0_erode:.4f}s")
            if dilate_iterations > 0: t0_dilate = time.time(); processed_binary = cv2.dilate(processed_binary,
                                                                                             morph_kernel,
                                                                                             iterations=dilate_iterations); t1_dilate = time.time(); print(
                f"[TIME][InternalGeom] Dilation ({dilate_iterations} iter): {t1_dilate - t0_dilate:.4f}s")
            if prepare_display_images: processed_binary_for_display = processed_binary.copy()  # Store for return

            # --- 4. Optional Morphological Smoothing (Closing) ---
            t0_morph = time.time()
            if enable_smoothing:
                smoothed_binary = cv2.morphologyEx(processed_binary, cv2.MORPH_CLOSE, morph_kernel)
                print("[Info][InternalGeom] Applied morphological closing (smoothing).")
            else:
                smoothed_binary = processed_binary  # Use the result from erode/dilate directly
                print("[Info][InternalGeom] Skipped morphological closing (smoothing disabled).")
            t1_morph = time.time();
            print(f"[TIME][InternalGeom] Smoothing Step (conditional): {t1_morph - t0_morph:.4f}s")

            # --- 5. Find Max Vertical Column Height (Prioritizing Middle) ---
            t0_col_height = time.time()
            img_height, img_width = smoothed_binary.shape
            min_req_height = int(min_col_height_ratio * img_height)
            min_req_height = 5
            target_pixel_value = 0 if not binary_inverted else 255;
            print(
                f"[Info][InternalGeom] Searching for target pixel value: {target_pixel_value} (binary_inverted={binary_inverted})");
            edge_width_px = int(col_edge_ignore_ratio * img_width);
            middle_start_x = edge_width_px;
            middle_end_x = img_width - edge_width_px - 1;
            max_height_overall = 0;
            max_height_middle = 0
            for x in range(img_width):
                max_height_in_col = 0;
                current_run_height = 0;
                in_run = False;
                col_run_start_y = -1;
                col_run_end_y = -1;
                potential_best_in_col = None
                for y in range(img_height):
                    pixel = smoothed_binary[y, x]
                    if pixel == target_pixel_value:
                        if not in_run: in_run = True; col_run_start_y = y
                        current_run_height += 1
                    else:
                        if in_run: in_run = False; col_run_end_y = y - 1;
                        if current_run_height > max_height_in_col: max_height_in_col = current_run_height; potential_best_in_col = {
                            'height': current_run_height, 'x': x, 'y_start': col_run_start_y,
                            'y_end': col_run_end_y}
                        current_run_height = 0
                if in_run: col_run_end_y = img_height - 1;
                if current_run_height > max_height_in_col: max_height_in_col = current_run_height; potential_best_in_col = {
                    'height': current_run_height, 'x': x, 'y_start': col_run_start_y, 'y_end': col_run_end_y}
                if max_height_in_col > max_height_overall: max_height_overall = max_height_in_col; max_height_info_overall = potential_best_in_col
                is_in_middle = (middle_start_x <= x <= middle_end_x)
                if is_in_middle and max_height_in_col > max_height_middle: max_height_middle = max_height_in_col; max_height_info_middle = potential_best_in_col
            t1_col_height = time.time();
            print(f"[TIME][InternalGeom] Max Column Height Search: {t1_col_height - t0_col_height:.4f}s")

            # --- Select the best column (prioritize middle) ---
            selected_max_height = 0;
            selected_max_height_info = None
            if max_height_middle > 0:
                selected_max_height = max_height_middle;
                selected_max_height_info = max_height_info_middle;
                print(
                    f"[Info][InternalGeom] Prioritizing middle column: x={selected_max_height_info['x']}, height={selected_max_height}")
            elif max_height_overall > 0:
                selected_max_height = max_height_overall;
                selected_max_height_info = max_height_info_overall;
                print(
                    f"[Info][InternalGeom] No middle column found, using overall best: x={selected_max_height_info['x']}, height={selected_max_height}")
            else:
                return False, f"InternalGeom_NG: No vertical run of target pixels ({target_pixel_value}) found.", None, None, cropped_deskewed_for_display, processed_binary_for_display, None

            # --- Check if the selected column meets the minimum height ratio ---
            if selected_max_height < min_req_height:
                measured_distance_pixels = float(selected_max_height)
                reason = f"InternalGeom_NG: Selected column height ({selected_max_height}px) below threshold ({min_req_height}px)."
                return False, reason, None, measured_distance_pixels, cropped_deskewed_for_display, processed_binary_for_display, None

            # --- Calculate Distance (Apply Offset BEFORE Conversion) ---
            measured_distance_pixels = float(selected_max_height)
            print(
                f"[Info][InternalGeom] Measured max target pixel column height: {measured_distance_pixels:.1f}px at x={selected_max_height_info['x']}")

            adjusted_distance_pixels = measured_distance_pixels + additional_height_pixels
            print(
                f"[Info][InternalGeom] Adjusted pixel height (+{additional_height_pixels}px offset): {adjusted_distance_pixels:.1f}px")

            measured_distance_mm = adjusted_distance_pixels * effective_mm_per_pixel
            print(f"[Info][InternalGeom] Calculated final distance: {measured_distance_mm:.3f} mm")

            # --- Prepare Annotated Binary Image for Display (if requested) ---
            if prepare_display_images:
                processed_binary_annotated = cv2.cvtColor(smoothed_binary, cv2.COLOR_GRAY2BGR)
                # Draw the measured column
                if selected_max_height_info['x'] != -1:
                    col_x = selected_max_height_info['x']
                    col_y_start = selected_max_height_info['y_start']
                    col_y_end = selected_max_height_info['y_end']
                    cv2.line(processed_binary_annotated, (col_x, col_y_start), (col_x, col_y_end), (0, 255, 0),
                             2)  # Green line
                # Draw the arrow representing the *adjusted* distance
                arrow_color = (0, 255, 255);
                arrow_thickness = 1
                arrow_x = selected_max_height_info['x'] if selected_max_height_info['x'] != -1 else img_width // 2
                arrow_start_y = selected_max_height_info['y_end'] if selected_max_height_info[
                                                                         'x'] != -1 else img_height - 1
                arrow_end_y = selected_max_height_info['y_start'] if selected_max_height_info[
                                                                         'x'] != -1 else arrow_start_y - int(
                    round(measured_distance_pixels))  # Arrow shows original measurement
                arrow_start_y = max(0, min(img_height - 1, arrow_start_y));
                arrow_end_y = max(0, min(img_height - 1, arrow_end_y));
                arrow_x = max(0, min(img_width - 1, arrow_x))
                cv2.arrowedLine(processed_binary_annotated, (arrow_x, arrow_start_y), (arrow_x, arrow_end_y),
                                arrow_color, arrow_thickness, tipLength=0.05)
                cv2.arrowedLine(processed_binary_annotated, (arrow_x, arrow_end_y), (arrow_x, arrow_start_y),
                                arrow_color, arrow_thickness, tipLength=0.05)
                # Text shows the final calculated mm value (after offset and conversion)
                dist_text = f"{measured_distance_mm:.2f}mm ({measured_distance_pixels:.1f}px + {additional_height_pixels}px)"
                dist_text_color = arrow_color;
                dist_font_scale = 0.4;
                dist_thickness = 1;
                (tw_dist, th_dist), baseline_dist = cv2.getTextSize(dist_text, cv2.FONT_HERSHEY_SIMPLEX,
                                                                    dist_font_scale, dist_thickness);
                text_x_dist = min(img_width - tw_dist - 2, arrow_x + 5);
                text_y_dist = (arrow_start_y + arrow_end_y) // 2 + th_dist // 2;
                cv2.putText(processed_binary_annotated, dist_text, (text_x_dist, text_y_dist),
                            cv2.FONT_HERSHEY_SIMPLEX, dist_font_scale, dist_text_color, dist_thickness, cv2.LINE_AA)

            # --- Compare with Range (Using min/max distance) ---
            total_geom_time = time.time() - start_geom_time  # Calculate time before return
            print(f"[TIME][InternalGeom] Total Check Duration: {total_geom_time:.4f}s")

            if min_dist_mm <= measured_distance_mm <= max_dist_mm:
                # Return status, reason, measurements, and prepared intermediate images
                return True, "OK", measured_distance_mm, measured_distance_pixels, cropped_deskewed_for_display, processed_binary_for_display, processed_binary_annotated
            else:
                reason = f"InternalGeom_NG: Final distance {measured_distance_mm:.3f}mm (adj_px:{adjusted_distance_pixels:.1f}) outside range [{min_dist_mm:.3f}, {max_dist_mm:.3f}]mm"
                # Return status, reason, measurements, and prepared intermediate images
                return False, reason, measured_distance_mm, measured_distance_pixels, cropped_deskewed_for_display, processed_binary_for_display, processed_binary_annotated

        except Exception as e:
            print(f"[Error][InternalGeom] Unexpected error during check: {e}\n{traceback.format_exc()}")
            # Return status, reason, and None for measurements/images on error
            return False, f"InternalGeom_Error: Processing failed - {e}", None, None, None, None, None
    # --- END check_internal_geometry METHOD ---
